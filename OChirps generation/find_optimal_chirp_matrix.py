from geneticalgorithm2 import geneticalgorithm2 as ga
from geneticalgorithm2 import AlgorithmParams
from geneticalgorithm2 import Selection
import numpy as np
from numpy.core.fromnumeric import reshape
from scipy.signal import chirp
from scipy.signal import oaconvolve
from multiprocessing import Process, Value
from chirp_generator import optimizer

M = 4
fs = 10000
fe = 20000

# Taken from the optimizer function of chirp_generator, but made faster
def optimizer_fast(signal_set):
    """Return an optimization parameter for the given signal set."""
    M = signal_set.shape[0]
    autocor_peaks_sidelobes = np.zeros((M, 1))
    crosscorrelations = np.zeros((M, M, len(oaconvolve(signal_set[1], np.flip(signal_set[1]), 'valid'))))
    crosscor_peaks = np.zeros((M, M - 1))

    # get cross-correlations between each of the signals
    for i in range(M):
        for j in range(M):
            if i >= j:
                crosscorrelations[i][j] = oaconvolve(signal_set[i], np.flip(signal_set[j]), 'valid')

    # for m in range(M):
    #     peak_index = np.argmax(crosscorrelations[m][m])
    #     autocor_without_mainlobe = np.concatenate((crosscorrelations[m][m][:peak_index - 150],
    #                                                crosscorrelations[m][m][peak_index + 150:]))
    #     autocor_peaks_sidelobes[m] = np.max(autocor_without_mainlobe)
    #     n = 0
    #     for k in range(M):
    #         if m > k:
    #             crosscor_peaks[m][n] = np.max(crosscorrelations[k][m])
    #             n += 1
    # c_max = np.amax(crosscor_peaks)
    # a_max = np.max(autocor_peaks_sidelobes)
    min_autocors = np.zeros(M)
    indx = 0
    for m in range(M):
        min_autocors[m] = np.max(np.abs(crosscorrelations[m][m]))
    max_crosscorrs = np.zeros(int(np.sum(np.linspace(1, M-1))))
    for m in range(M):
        for n in range(M):
            if m > n:
                max_crosscorrs[indx] = np.max(np.abs(crosscorrelations[m][n]))
                indx += 1
    crosscor_max = np.max(max_crosscorrs)
    autocor_min = np.min(min_autocors)
    return crosscor_max/autocor_min

def convert_chrirps_to_signals(symbols: list, M: int, T: float, fsample: int) -> list:
    """
        Convert the chirp symbols from `construct_chirps` to actual chirp signals.
        M should reflect the symbols, T and fsample dictate what the signal looks like
    """
    Tb = T / M
    t = np.linspace(0, Tb, int(np.ceil(Tb * fsample)))

    def encode(symbol, Tb, t):
        c = np.array([])
        for subchirp in symbol:
            subchirp_signal = chirp(t, subchirp[0], Tb, subchirp[1])
            c = np.append(c, subchirp_signal)
        return c

    signals = []
    for s in symbols:
        signals.append(encode(s, Tb, t))

    return signals


def construct_chirps(R: list, M: int, fs: int, fe: int) -> list:
    """
        Construct chirps based on the matrix R.
        M should reflect the matrix R. fs and fe are the lower and upper bound of
        the bandwidth
    """
    symbols = []
    for row in R:
        chirp = []
        # We calculate the hybrid chirps here. We could also only use upward or downward chirps.
        for i, m in enumerate(row):
            if M != 1:
                fsm = fs + ((m-1)*(fe - fs))/M
                fem = fsm + (fe - fs)/M
            else:
                fsm = fs
                fem = fe

            if m % 2 == i % 2:
                chirp.append((fem, fsm))
            else:
                chirp.append((fsm, fem))

        symbols.append(chirp)
    return symbols


def evaluate_signals(signals: list) -> float:
    """
        Evaluate the chirp signals based on their cross correlation output
        We need the signals to be orthogonal, so the max value in their cross correlation should be as low as possible.
        Moreover, we want to minimize the side-lobes of the autocorrelation

        Pass the signals generated by `convert_chrirps_to_signals` to this function to get a metric (lower is better).
    """
    max_cross_correlations = []
    max_side_lobe = []

    def get_max_correlation(s: np.array, signal: np.array) -> float:
        return np.max(np.abs(oaconvolve(np.flip(s), signal, mode="same")))

    def get_max_side_lobe(s: np.array, signal: np.array) -> float:
        correlation = oaconvolve(np.flip(s), signal, mode="same")

        peak = np.argmax(correlation)
        valley = np.argmin(correlation)
        peak_width = np.abs(peak - valley)

        correlation_without_peak = np.concatenate((correlation[:peak - peak_width], correlation[peak + peak_width:]))

        return np.max(correlation_without_peak)

    for i, signal in enumerate(signals):
        for j, s in enumerate(signals):
            if i > j:
                max_cross_correlations.append(get_max_correlation(s, signal))
            if i == j:
                pass
                max_side_lobe.append(get_max_side_lobe(s, signal))

    # We want to minimize the cross correlation as well as the side lobe
    return np.max(max_cross_correlations)**2 + np.max(max_side_lobe)**2


def matrix_valid(R: list) -> bool:
    """
        Check wether matrix R is valid to construct orthogonal chirps
        This means that all rows and columns must contain only unique values (like a sudoku)
    """
    # Make sure every row has only unique values
    for row in R:
        if len(row) != len(np.unique(row)):
            return False

    # Make sure every column has only unique values
    for i in range(M):
        col = R[:,i]
        if len(col) != len(np.unique(col)):
            return False

    return True


def evaluate_matrix(R: list):
    """
        Evaluate the matrix R on it's orthogonality and cross correlation performance
        returns a metric for how well it does (lower is better)
    """
    # Re-construct the matrix from a flat array
    R = np.reshape(R, (M, M))

    chirps = construct_chirps(R, M, fs, fe)
    signals = convert_chrirps_to_signals(chirps, M, 0.1, 44100)
    # evaluation = evaluate_signals(signals)
    evaluation = optimizer(np.array(signals))
    # evaluation = optimizer_fast(np.array(signals))

    penalty = 0
    if not matrix_valid(R):
        penalty += evaluation * 1000

    return evaluation + penalty


def generate_valid_starting_matrix(M: int) -> list:
    """
        Generate a valid random matrix to help kickstart the first generation
        Simply generates a valid row and then simply shift it right once for every row below.
        I've manually checked that this gives a valid matrix, but I don't know whether this guarantees one.
    """
    l = np.arange(1, M+1)
    np.random.shuffle(l)
    R = [l]
    for _ in range(M-1):
        R.append(np.roll(R[-1], 1))

    # Shuffle rows and columns
    # print(R)
    np.random.shuffle(R)
    # print(R)
    R = np.transpose(R)
    # print(R)
    np.random.shuffle(R)
    # print(R)
    R = np.transpose(R)
    # print(R)

    return R


def main():
    np.random.seed(None)

    pop_size = 5000
    model = ga( function=evaluate_matrix,
                dimension=M*M,
                variable_type='int',
                variable_boundaries=np.array([[1, M]]*M*M),
                algorithm_parameters=AlgorithmParams(
                     max_num_iteration = None,
                     population_size = pop_size,
                     mutation_probability = 0.5,
                     elit_ratio = 0.01,
                     crossover_probability = 1,
                     parents_portion = 0.3,
                     crossover_type = 'segment',
                     mutation_type = 'uniform_by_center',
                     selection_type = Selection.ranking(),
                     max_iteration_without_improv = 1
                     ))

    print("Generating starting population...")
    min_val = np.iinfo(int).max
    samples = np.random.randint(1, M, (pop_size, M*M))
    for i in range(pop_size):
        start_matrix = generate_valid_starting_matrix(M)
        samples[i] = np.array(start_matrix).flatten()
        val = evaluate_matrix(samples[i])
        if val < min_val:
            min_val = val

    print(f"Best starting value: {min_val}")

    model.run(set_function=ga.set_function_multiprocess(evaluate_matrix, n_jobs=12), start_generation=samples, remove_duplicates_generation_step=50)

    result = np.reshape(model.best_variable, (M, M))
    valid = matrix_valid(result)

    print(f"\nDone, result is \n{valid} : \n{result}")

if __name__ == '__main__':
    main()
