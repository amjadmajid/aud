from ensurepip import version
import pytorch_lightning as pl
from audioDataLoader import AudioDataModule
from audioModel import AudioModel
from pytorch_lightning.callbacks import ModelCheckpoint
from audioCallBacks import CustomCallback
from pytorch_lightning.loggers import CSVLogger
import torch

#directory where your version of the model is stored
#edit for proper version, each training procedure started generates its own version number
#each version will store up to k models, depending on the
#save_top_k param within the train() method.
versionPath = "C:\Users\Nilsv\Documents\GitHub\aud\Pytorch_lightning\version_12"

#for the checkpoints generated by audioTraining.py
#models should have the layout name:
# modello-figo-{epoch}--{val_loss:0.4f}.ckpt
modelName = "modello-figo-3--0.002.ckpt"

#get data to eval on



model = AudioModel()

#setup model for evaluation mode
checkpoint = torch.load(versionPath + modelName)
model.load_state_dict(checkpoint["state_dict"])
model.eval()