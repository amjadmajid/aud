from ensurepip import version
import pytorch_lightning as pl
from audioDataLoader import AudioDataModule
from audioModel import AudioModel
from pytorch_lightning.callbacks import ModelCheckpoint
from audioCallBacks import CustomCallback
from pytorch_lightning.loggers import CSVLogger
import torch

#directory where your version of the model is stored
#edit for proper version, each training procedure started generates its own version number
#each version will store up to k models, depending on the
#save_top_k param within the train() method.
versionPath = "C:\\Users\\Nils\\Documents\\GitHub\\aud\Pytorch_lightning\lightning_logs\\version_15\checkpoints\modello-figo-epoch=64--val_loss=0.0739.ckpt"

#for the checkpoints generated by audioTraining.py
#models should have the layout name:
# modello-figo-{epoch}--{val_loss:0.4f}.ckpt
modelName = ""

#get data to eval on

def test():
    data_m = AudioDataModule()
    model = AudioModel()
    custom_call = CustomCallback()

    checkpoint_p = ModelCheckpoint(
        monitor="val_loss",
        mode="min",
        verbose=True,
        filename="modello-figo-{epoch}--{val_loss:0.4f}",
        save_top_k=3,
        
    )

    trainer = pl.Trainer(
        gpus = -1,
        accelerator="gpu",
        callbacks=[checkpoint_p, custom_call],
        min_epochs=1,
        max_epochs=50,
        logger=CSVLogger(save_dir="")
    )

    checkpoint = torch.load(versionPath + modelName)
    model.load_state_dict(checkpoint["state_dict"])
    trainer.test(model, dataloaders=data_m)


if __name__ == "__main__":
    test()

#setup model for evaluation mode


